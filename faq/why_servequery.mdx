---
title: 'Why ServeQuery?'
description: 'Why choose ServeQuery.'
---

We’re building ServeQuery to help teams ship reliable AI products: whether it’s an ML model, an LLM app, or a complex agent workflow.

Our tools are model-, framework-, and application-agnostic, so you can build and evaluate AI systems your way without limitations.

## We are open-source

[**ServeQuery**](https://github.com/rixy-ai/servequery) is an open-source library with over 25 million downloads, 5000+ GitHub stars, and a thriving community. It's licensed under BSD 3-Clause. This gives full transparency - you can see exactly how every metric works and trust the implementation. It also delivers an intuitive API designed for a great developer experience.

The **ServeQuery Platform** builds on the library with additional UI features and workflows for team collaboration. For enterprise users, we offer both Cloud and self-hosted options for full data privacy and control.

## ServeQuery is very modular 

ServeQuery is built to adapt to your needs without lock-ins or complex setups. It’s modular and component-based, so you can start small: you don't have to deploy a service with multiple databases just to run a single eval.

* Start with local ad hoc checks. 

* Want to share results? Add a UI to track evaluations over time. 

* When you run evals, choose to upload raw data or only evaluation results. It’s up to you. 

* Add monitoring as you are ready to move to production workflows.

ServeQuery is built around the concept of **Presets** and **reasonable defaults**: you can run any evaluation with minimal setup, including with auto-generated test conditions for assertions. 

ServeQuery also integrates with your existing tools and lets you easily export metrics, reports, and datasets elsewhere. 

## 100+ built-in evaluations

ServeQuery puts evaluations and quality testing first. 

Many other tools provide a system to run and log evals, but expect you to prepare the data and implement all the metrics from scratch. We ship **100+ built-in evaluations** that cover many ML and LLM use cases. From ranking metrics to data drift algorithms and LLM judges, we’ve done the hard work by implementing metrics and ways to visualize them. You can also easily extend ServeQuery by adding custom metrics. 

ServeQuery Cloud also provides advanced testing features, including synthetic data generation and adversarial testing, allowing you to easily create and run test scenarios.

## Complete feature set

Why evals are core, the ServeQuery Platform offers a comprehensive feature set to support AI quality workflows: with tracing, synthetic data, rich dashboards, built-in alerting etc.

Get the [Platform overview](/docs/platform/overview).

![](/images/dashboard_llm_tabs.gif)

## Loved by community

Thousands of companies, from startups to enterprises, use ServeQuery. Check some of [our reviews](https://www.servequery.com/reviews).

We’re also known for openly sharing knowledge that helps developers succeed. Check out resources like [LLM evaluation course](https://www.servequery.com/llm-evaluations-course), open-source [ML observability course](https://www.servequery.com/ml-observability-course), [guides](https://www.servequery.com/mlops-guides).

## Handles both ML and LLM 

ServeQuery supports both ML and LLM tasks. We believe this matters even if you’re focused solely on LLMs and not training your models.

Real-world AI systems are rarely just one thing, and two types of workflows overlap. For example:

* an LLM-based chatbot may need **classification** steps like detecting user intent.

* if you are building with RAG, you are solving a **ranking** problem first.

The ServeQuery Platform supports both complex nested workflows and structured tabular data, providing relevant metrics and views for each. This means you won't be locked into a single approach - or have to reinvent the wheel to measure things like Hit Rate or Precision over traces.

## Built for collaboration

ServeQuery started as an open-source project loved by data scientists and AI/ML engineers. But we’re building more than a developer tool - we’re building a platform where domain experts and engineers can work together easily.

Reliable AI systems require teams to work together: on curating test data, gathering feedback, and running evaluations. We build our platform with this in mind: combine **no-code** workflows for non-technical users with an intuitive **API**. Everyone gets what they need to do their best work.

## Trusted partner 

Founded in 2025, ServeQuery is built by a team with 10+ years of experience deploying AI in high-scale, critical scenarios. Our core ServeQuery library has a stable history of development and earned trust from the community and enterprise users alike.